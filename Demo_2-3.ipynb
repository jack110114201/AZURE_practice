{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas基礎使用 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataframe from list\n",
      "    name  math score  english score\n",
      "0  isaac          60             50\n",
      "1  julie          90             70\n",
      "2   alex          30             40\n",
      "create dataframe from dict\n",
      "    name  math score  english score\n",
      "0  isaac          60             50\n",
      "1  julie          90             70\n",
      "2   alex          30             40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_list = [('isaac', 60, 50),('julie', 90, 70),('alex', 30, 40)]\n",
    "header = ['name','math score','english score']\n",
    "df_from_list = pd.DataFrame.from_records(my_list, columns=header)\n",
    "\n",
    "print('create dataframe from list')\n",
    "print(df_from_list)\n",
    "\n",
    "\n",
    "\n",
    "my_dict = \\\n",
    "[{'name':'isaac', 'math score':60,'english score':50},\n",
    "{'name':'julie', 'math score':90,'english score':70},\n",
    "{'name':'alex', 'math score':30,'english score':40}\n",
    "]\n",
    "\n",
    "df_from_dict = pd.DataFrame(my_dict, columns=['name', 'math score', 'english score'])\n",
    "\n",
    "print('create dataframe from dict')\n",
    "print(df_from_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pandas Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot\n",
      "0    1985      20   1228      81   1328      64    N      0\n",
      "1    1985      25   1106      77   1354      70    H      0\n",
      "2    1985      25   1112      63   1223      56    H      0\n",
      "3    1985      25   1165      70   1432      54    H      0\n",
      "4    1985      25   1192      86   1447      74    H      0\n",
      "        Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot\n",
      "145284    2016     132   1114      70   1419      50    N      0\n",
      "145285    2016     132   1163      72   1272      58    N      0\n",
      "145286    2016     132   1246      82   1401      77    N      1\n",
      "145287    2016     132   1277      66   1345      62    N      0\n",
      "145288    2016     132   1386      87   1433      74    N      0\n",
      "              Season         Daynum          Wteam         Wscore  \\\n",
      "count  145289.000000  145289.000000  145289.000000  145289.000000   \n",
      "mean     2001.574834      75.223816    1286.720646      76.600321   \n",
      "std         9.233342      33.287418     104.570275      12.173033   \n",
      "min      1985.000000       0.000000    1101.000000      34.000000   \n",
      "25%      1994.000000      47.000000    1198.000000      68.000000   \n",
      "50%      2002.000000      78.000000    1284.000000      76.000000   \n",
      "75%      2010.000000     103.000000    1379.000000      84.000000   \n",
      "max      2016.000000     132.000000    1464.000000     186.000000   \n",
      "\n",
      "               Lteam         Lscore          Numot  \n",
      "count  145289.000000  145289.000000  145289.000000  \n",
      "mean     1282.864064      64.497009       0.044387  \n",
      "std       104.829234      11.380625       0.247819  \n",
      "min      1101.000000      20.000000       0.000000  \n",
      "25%      1191.000000      57.000000       0.000000  \n",
      "50%      1280.000000      64.000000       0.000000  \n",
      "75%      1375.000000      72.000000       0.000000  \n",
      "max      1464.000000     150.000000       6.000000  \n",
      "Season    2016\n",
      "Daynum     132\n",
      "Wteam     1464\n",
      "Wscore     186\n",
      "Lteam     1464\n",
      "Lscore     150\n",
      "Wloc         N\n",
      "Numot        6\n",
      "dtype: object\n",
      "   Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot\n",
      "0    1985      25   1106      77   1354      70    H      0\n",
      "1    1985      25   1112      63   1223      56    H      0\n",
      "2    1985      25   1165      70   1432      54    H      0\n",
      "3    1985      25   1192      86   1447      74    H      0\n",
      "4    1985      25   1218      79   1337      78    H      0\n",
      "   Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot\n",
      "0      20   1228      81   1328      64    N      0\n",
      "1      25   1106      77   1354      70    H      0\n",
      "2      25   1112      63   1223      56    H      0\n",
      "3      25   1165      70   1432      54    H      0\n",
      "4      25   1192      86   1447      74    H      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# use pandas to read csv file\n",
    "df = pd.read_csv('RegularSeasonCompactResults.csv')\n",
    "\n",
    "# print first five row\n",
    "print(df.head())\n",
    "\n",
    "# print last five row\n",
    "print(df.tail())\n",
    "\n",
    "# statistics on the dataframe\n",
    "print(df.describe())\n",
    "\n",
    "# print max value of each column\n",
    "print(df.max())\n",
    "\n",
    "# print Wscore that is greater than 150\n",
    "df[df['Wscore'] > 150]\n",
    "\n",
    "# drop rows and reset index\n",
    "df_drop_row = df.drop(df.index[0])\n",
    "df_reset_index1 = df_drop_row.reset_index(drop=True)\n",
    "print(df_reset_index1.head())\n",
    "\n",
    "# drop columns\n",
    "df_drop_column = df.drop('Season', axis=1)\n",
    "print(df_drop_column.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin dataframe\n",
      "   size  number_room  house_price house_type\n",
      "0  40.0          3.0          800        old\n",
      "1  29.0          5.0          700      young\n",
      "2  33.0          2.0          670      young\n",
      "3   NaN          2.0          770        old\n",
      "4   NaN          NaN          870      young\n",
      "drop row that contain any missing value\n",
      "   size  number_room  house_price house_type\n",
      "0  40.0          3.0          800        old\n",
      "1  29.0          5.0          700      young\n",
      "2  33.0          2.0          670      young\n",
      "fill missing value with mean\n",
      "   size  number_room  house_price house_type\n",
      "0  40.0          3.0          800        old\n",
      "1  29.0          5.0          700      young\n",
      "2  33.0          2.0          670      young\n",
      "3  34.0          2.0          770        old\n",
      "4  34.0          NaN          870      young\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load csv file\n",
    "df = pd.read_csv('demo.csv')\n",
    "\n",
    "print('origin dataframe')\n",
    "print(df)\n",
    "\n",
    "print('drop row that contain any missing value')\n",
    "# drop row that contain any missing value\n",
    "df_no_missing = df.dropna()\n",
    "print(df_no_missing)\n",
    "\n",
    "print('fill missing value with mean')\n",
    "# fill missing value with mean \n",
    "df[\"size\"].fillna(df[\"size\"].mean(), inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin dataframe\n",
      "   size  number_room  house_price house_type\n",
      "0  40.0          3.0          800        old\n",
      "1  29.0          5.0          700      young\n",
      "2  33.0          2.0          670      young\n",
      "3   NaN          2.0          770        old\n",
      "4   NaN          NaN          870      young\n",
      "encode category\n",
      "   size  number_room  house_price  house_type\n",
      "0  40.0          3.0          800           0\n",
      "1  29.0          5.0          700           1\n",
      "2  33.0          2.0          670           1\n",
      "3   NaN          2.0          770           0\n",
      "4   NaN          NaN          870           1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load csv file\n",
    "df = pd.read_csv('demo.csv')\n",
    "\n",
    "print('origin dataframe')\n",
    "print(df)\n",
    "\n",
    "print('encode category')\n",
    "df['house_type'] = pd.Categorical(df['house_type']).codes\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn基礎使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before splitting......\n",
      "x: [[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]\n",
      " [18 19]]\n",
      "\n",
      "y: [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "shape of x: (10, 2)\n",
      "shape of y: (10,)\n",
      "\n",
      "after splitting......\n",
      "x_train: [[12 13]\n",
      " [ 8  9]\n",
      " [16 17]\n",
      " [10 11]\n",
      " [ 6  7]\n",
      " [ 2  3]\n",
      " [14 15]]\n",
      "\n",
      "x_test: [[18 19]\n",
      " [ 4  5]\n",
      " [ 0  1]]\n",
      "\n",
      "y_train: [6 4 8 5 3 1 7]\n",
      "\n",
      "y_test: [9 2 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = np.arange(20).reshape((10, 2)), np.arange(10)\n",
    "\n",
    "print('before splitting......')\n",
    "\n",
    "print(\"x: {}\\n\".format(x))\n",
    "print(\"y: {}\\n\".format(y))\n",
    "\n",
    "print(\"shape of x: {}\".format(x.shape))\n",
    "print(\"shape of y: {}\\n\".format(y.shape))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "print('after splitting......')\n",
    "\n",
    "print(\"x_train: {}\\n\".format(x_train))\n",
    "print(\"x_test: {}\\n\".format(x_test))\n",
    "\n",
    "print(\"y_train: {}\\n\".format(y_train))\n",
    "print(\"y_test: {}\\n\".format(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-score Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of x_train: [4.00000000e+02 0.00000000e+00 3.33333333e-01]\n",
      "std of x_train: [355.9026084    0.81649658   1.24721913]\n",
      "\n",
      "mean of x_scale: [4.00000000e+02 0.00000000e+00 3.33333333e-01]\n",
      "std of x_scale: [355.9026084    0.81649658   1.24721913]\n",
      "\n",
      "after standardiztion......\n",
      "x_train: [[-0.84292723 -1.22474487  1.33630621]\n",
      " [ 1.40487872  0.         -0.26726124]\n",
      " [-0.56195149  1.22474487 -1.06904497]]\n",
      "apply same mean and std to new data(test data)\n",
      "\n",
      "x_test: [[-1.12671273  1.22474487 -0.26726124]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.array([[ 100., -1.,  2.],\n",
    "                    [ 900.,  0.,  0.],\n",
    "                    [ 200.,  1., -1.]])\n",
    "\n",
    "\n",
    "print(\"mean of x_train: {}\".format(x_train.mean(axis=0)))\n",
    "print(\"std of x_train: {}\\n\".format(x_train.std(axis=0)))\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "print(\"mean of x_scale: {}\".format(scaler.mean_))\n",
    "print(\"std of x_scale: {}\\n\".format(scaler.scale_))\n",
    "\n",
    "# apply mean and std to standardize data\n",
    "x_train = scaler.transform(x_train)\n",
    "\n",
    "print(\"after standardiztion......\")\n",
    "print('x_train: {}'.format(x_train))\n",
    "\n",
    "\n",
    "x_test = np.array([[-1., 1., 0.]])\n",
    "print(\"apply same mean and std to new data(test data)\\n\")\n",
    "\n",
    "x_test = scaler.transform(x_test)\n",
    "print('x_test: {}'.format(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after standardiztion......\n",
      "x_train: [[0.5        0.         1.        ]\n",
      " [1.         0.5        0.33333333]\n",
      " [0.         1.         0.        ]]\n",
      "apply same transformation to new data(test data)\n",
      "\n",
      "x_test: [[-1.5         0.          1.66666667]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "\n",
    "print(\"after standardiztion......\")\n",
    "print('x_train: {}'.format(x_train))\n",
    "\n",
    "\n",
    "x_test = np.array([[ -3., -1.,  4.]])\n",
    "print(\"apply same transformation to new data(test data)\\n\")\n",
    "\n",
    "x_test = scaler.transform(x_test)\n",
    "print('x_test: {}'.format(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.4\n",
      "r2 score: -0.6666666666666665\n",
      "number of correct sample: 3\n",
      "accuracy: 0.6\n",
      "confusion matrix: [[2 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
    "\n",
    "y_test = [0, 1, 0 , 1, 0]\n",
    "y_pred = [1, 0, 0 , 1, 0]\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "num_correct_samples = accuracy_score(y_test, y_pred, normalize=False)\n",
    "con_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Mean squared error: {}\".format(mse))\n",
    "print('r2 score: {}'.format(r2))\n",
    "print('number of correct sample: {}'.format(num_correct_samples))\n",
    "print('accuracy: {}'.format(accuracy))\n",
    "print('confusion matrix: {}'.format(con_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
